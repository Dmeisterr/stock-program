{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataAdjust.py\n",
    "3. Drop rows with any N/A values.\n",
    "4. Group the data by 'Symbol'.\n",
    "5. For each group, create a summary row containing:\n",
    "    - Symbol\n",
    "    - Start Date\n",
    "    - End Date\n",
    "    - Original Adjusted Close\n",
    "    - Final Adjusted Close\n",
    "    - Original Earnings\n",
    "    - Final Earnings\n",
    "    - Original P/E Ratio\n",
    "    - Final P/E Ratio\n",
    "6. Write the summary data to 'stocks_summary_one_row.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV\n",
    "df = pd.read_csv(\"stocks_calc_final.csv\")\n",
    "\n",
    "# Ensure Date is recognized as a datetime for proper sorting\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with any N/A values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Group by symbol\n",
    "grouped = df_clean.groupby(\"Symbol\", group_keys=True)\n",
    "\n",
    "summary_rows = []\n",
    "for symbol, group in grouped:\n",
    "    # Sort by Date so the first row is the earliest date, the last row is the latest date\n",
    "    group_sorted = group.sort_values(\"Date\")\n",
    "    first_row = group_sorted.iloc[0]\n",
    "    last_row = group_sorted.iloc[-1]\n",
    "    \n",
    "    # Create a single summary row for this symbol\n",
    "    summary_rows.append({\n",
    "        \"Symbol\": symbol,\n",
    "        \"Start Date\": first_row[\"Date\"].strftime(\"%Y-%m-%d\"),\n",
    "        \"End Date\": last_row[\"Date\"].strftime(\"%Y-%m-%d\"),\n",
    "        \"Original Adjusted Close\": first_row[\"Adjusted Close\"],\n",
    "        \"Final Adjusted Close\": last_row[\"Adjusted Close\"],\n",
    "        \"Original Earnings\": first_row[\"Earnings\"],\n",
    "        \"Final Earnings\": last_row[\"Earnings\"],\n",
    "        \"Original P/E Ratio\": first_row[\"P/E Ratio\"],\n",
    "        \"Final P/E Ratio\": last_row[\"P/E Ratio\"]\n",
    "    })\n",
    "\n",
    "# Create a new DataFrame and write to CSV\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"stocks_summary_one_row.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script processes stock data from a CSV file, calculates trailing twelve months (TTM) earnings per share (EPS) \n",
    "and price-to-earnings (P/E) ratios, and outputs the results to a new CSV file.\n",
    "Steps:\n",
    "1. Read stock data from 'stocks_calc_final.csv'.\n",
    "2. Convert the 'Date' column to datetime format and sort the data by 'Symbol' and 'Date'.\n",
    "3. Group the data by 'Symbol'.\n",
    "4. For each group, calculate the TTM EPS and P/E ratios:\n",
    "    - Initialize 'EPS (ttm)' and 'P/E (ttm)' columns with NaN values.\n",
    "    - For each row, if there are enough previous rows (189 days), calculate the TTM EPS as the sum of earnings \n",
    "      from the current row and the rows 63, 126, and 189 days prior.\n",
    "    - Calculate the TTM P/E ratio as the adjusted close price divided by the TTM EPS.\n",
    "5. Concatenate the processed groups and write the final DataFrame to 'stocks_calc_final_with_ttm.csv'.\n",
    "Output:\n",
    "- 'stocks_calc_final_with_ttm.csv': A CSV file containing the original data along with the calculated 'EPS (ttm)' \n",
    "  and 'P/E (ttm)' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"stocks_calc_final.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"Symbol\", \"Date\"])\n",
    "\n",
    "output_groups = []\n",
    "\n",
    "for symbol, group in df.groupby(\"Symbol\", group_keys=False):\n",
    "    # Sort by date, reset index so each row has a clean 0..N index\n",
    "    group = group.sort_values(\"Date\").reset_index(drop=True)\n",
    "    \n",
    "    # Initialize columns\n",
    "    group[\"EPS (ttm)\"] = np.nan\n",
    "    group[\"P/E (ttm)\"] = np.nan\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        if i >= 189:  # Enough rows\n",
    "            earnings_values = [\n",
    "                group.at[i, \"Earnings\"],\n",
    "                group.at[i-63, \"Earnings\"],\n",
    "                group.at[i-126, \"Earnings\"],\n",
    "                group.at[i-189, \"Earnings\"]\n",
    "            ]\n",
    "            if all(pd.notna(earnings_values)) and all(earnings_values):\n",
    "                eps_ttm = sum(earnings_values)\n",
    "                group.at[i, \"EPS (ttm)\"] = eps_ttm\n",
    "                if eps_ttm != 0:\n",
    "                    group.at[i, \"P/E (ttm)\"] = group.at[i, \"Adjusted Close\"] / eps_ttm\n",
    "    \n",
    "    output_groups.append(group)\n",
    "\n",
    "final_df = pd.concat(output_groups, ignore_index=True)\n",
    "final_df.to_csv(\"stocks_calc_final_with_ttm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main stock data...\n",
      "Loading economic indicator data...\n",
      "Merging economic indicators with stock data...\n",
      "Saving final merged data to CSV...\n",
      "  Symbol       Date   Open   High    Low  Close  Adjusted Close    Volume  \\\n",
      "0      A 1999-11-18  45.50  50.00  40.00  44.00       28.452814  44739900   \n",
      "1      A 1999-11-19  42.94  43.00  39.81  40.38       26.111923  10897100   \n",
      "2      A 1999-11-22  41.31  44.00  40.06  44.00       28.452814   4705200   \n",
      "3      A 1999-11-23  42.50  43.63  40.25  40.25       26.027858   4274400   \n",
      "4      A 1999-11-24  40.13  41.94  40.00  41.06       26.551649   3464400   \n",
      "\n",
      "   Dividend Amount  Split Coefficient  ...  P/E Ratio  EPS (ttm)  P/E (ttm)  \\\n",
      "0              0.0                1.0  ...        NaN        NaN        NaN   \n",
      "1              0.0                1.0  ...        NaN        NaN        NaN   \n",
      "2              0.0                1.0  ...        NaN        NaN        NaN   \n",
      "3              0.0                1.0  ...        NaN        NaN        NaN   \n",
      "4              0.0                1.0  ...        NaN        NaN        NaN   \n",
      "\n",
      "     CPI  Fed_Funds_Rate  GDP_Per_Capita  Inflation_Rate   Real_GDP  \\\n",
      "0  168.3            5.42         49281.0        2.188027  13543.774   \n",
      "1  168.3            5.42         49281.0        2.188027  13543.774   \n",
      "2  168.3            5.42         49281.0        2.188027  13543.774   \n",
      "3  168.3            5.42         49281.0        2.188027  13543.774   \n",
      "4  168.3            5.42         49281.0        2.188027  13543.774   \n",
      "\n",
      "   Treasury_Yield  Unemployment_Rate  \n",
      "0            6.03                4.1  \n",
      "1            6.03                4.1  \n",
      "2            6.03                4.1  \n",
      "3            6.03                4.1  \n",
      "4            6.03                4.1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the main stock data file\n",
    "print(\"Loading main stock data...\")\n",
    "stock_df = pd.read_csv(\"../stocks_calc_final_with_ttm.csv\")\n",
    "stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Load economic indicator data files\n",
    "print(\"Loading economic indicator data...\")\n",
    "\n",
    "# CPI data\n",
    "cpi_df = pd.read_csv(\"../CPI.csv\")\n",
    "cpi_df[\"Date\"] = pd.to_datetime(cpi_df[\"Date\"], errors=\"coerce\")\n",
    "cpi_df.rename(columns={\"Value\": \"CPI\"}, inplace=True)\n",
    "\n",
    "# Federal Funds Rate data\n",
    "ffr_df = pd.read_csv(\"../FFR.csv\")\n",
    "ffr_df[\"Date\"] = pd.to_datetime(ffr_df[\"Date\"], errors=\"coerce\")\n",
    "ffr_df.rename(columns={\"Value\": \"Fed_Funds_Rate\"}, inplace=True)\n",
    "\n",
    "# GDP Per Capita data\n",
    "gdp_capita_df = pd.read_csv(\"../GDP_Capita.csv\")\n",
    "gdp_capita_df[\"Date\"] = pd.to_datetime(gdp_capita_df[\"Date\"], errors=\"coerce\")\n",
    "gdp_capita_df.rename(columns={\"Value\": \"GDP_Per_Capita\"}, inplace=True)\n",
    "\n",
    "# Inflation data\n",
    "inflation_df = pd.read_csv(\"../INFLATION.csv\")\n",
    "inflation_df[\"Date\"] = pd.to_datetime(inflation_df[\"Date\"], errors=\"coerce\")\n",
    "inflation_df.rename(columns={\"Value\": \"Inflation_Rate\"}, inplace=True)\n",
    "\n",
    "# Real GDP data\n",
    "real_gdp_df = pd.read_csv(\"../REAL_GDP.csv\")\n",
    "real_gdp_df[\"Date\"] = pd.to_datetime(real_gdp_df[\"Date\"], errors=\"coerce\")\n",
    "real_gdp_df.rename(columns={\"Value\": \"Real_GDP\"}, inplace=True)\n",
    "\n",
    "# Treasury Yield data\n",
    "treasury_df = pd.read_csv(\"../TREASURY_YIELD.csv\")\n",
    "treasury_df[\"Date\"] = pd.to_datetime(treasury_df[\"Date\"], errors=\"coerce\")\n",
    "treasury_df.rename(columns={\"Value\": \"Treasury_Yield\"}, inplace=True)\n",
    "\n",
    "# Unemployment data\n",
    "unemployment_df = pd.read_csv(\"../UNEMPLOYMENT.csv\")\n",
    "unemployment_df[\"Date\"] = pd.to_datetime(unemployment_df[\"Date\"], errors=\"coerce\")\n",
    "unemployment_df.rename(columns={\"Value\": \"Unemployment_Rate\"}, inplace=True)\n",
    "\n",
    "# Create a function to resample monthly data to daily with forward fill\n",
    "def resample_to_daily(df):\n",
    "    # Set Date as index\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Create a new date range at daily frequency from min to max date\n",
    "    date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "    \n",
    "    # Reindex to have all days, and forward fill missing values\n",
    "    df_daily = df.reindex(date_range).ffill()\n",
    "    \n",
    "    # Reset index to get Date as a column again\n",
    "    df_daily = df_daily.reset_index()\n",
    "    df_daily.rename(columns={'index': 'Date'}, inplace=True)\n",
    "    return df_daily\n",
    "# Resample each economic indicator DataFrame to daily frequency\n",
    "cpi_daily = resample_to_daily(cpi_df)\n",
    "ffr_daily = resample_to_daily(ffr_df)\n",
    "gdp_capita_daily = resample_to_daily(gdp_capita_df)\n",
    "inflation_daily = resample_to_daily(inflation_df)\n",
    "real_gdp_daily = resample_to_daily(real_gdp_df)\n",
    "treasury_daily = resample_to_daily(treasury_df)\n",
    "unemployment_daily = resample_to_daily(unemployment_df)\n",
    "# Merge all economic indicators with the main stock DataFrame\n",
    "print(\"Merging economic indicators with stock data...\")\n",
    "merged_df = stock_df.merge(cpi_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(ffr_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(gdp_capita_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(inflation_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(real_gdp_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(treasury_daily, on=\"Date\", how=\"left\")\n",
    "merged_df = merged_df.merge(unemployment_daily, on=\"Date\", how=\"left\")\n",
    "# Save the final merged DataFrame to CSV\n",
    "print(\"Saving final merged data to CSV...\")\n",
    "merged_df.to_csv(\"stocks_final_with_economic_indicators.csv\", index=False)\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(\"/Users/daniellott2/Documents/stock-program/src/data/stocks_final_with_economic_indicators.csv\")\n",
    "\n",
    "# Ensure Date is recognized as a datetime for proper sorting\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Sort by symbol and date\n",
    "df = df.sort_values([\"Symbol\", \"Date\"])\n",
    "\n",
    "# Calculate moving averages\n",
    "df[\"MA_50\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.rolling(window=50).mean())\n",
    "df[\"MA_200\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.rolling(window=200).mean())\n",
    "\n",
    "# Drop rows with any N/A values after moving averages calculation\n",
    "df = df.dropna(subset=[\"Adjusted Close\", \"MA_50\", \"MA_200\"])  # Only drop if key values are missing\n",
    "\n",
    "# Calculate price change over 1, 5, and 10 years\n",
    "df[\"Price_Change_1Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=252))\n",
    "df[\"Price_Change_5Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=1260))\n",
    "df[\"Price_Change_10Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=2520))\n",
    "\n",
    "df[\"MA_50/Adj_Close\"] = df[\"MA_50\"] / df[\"Adjusted Close\"]\n",
    "df[\"MA_200/Adj_Close\"] = df[\"MA_200\"] / df[\"Adjusted Close\"]\n",
    "\n",
    "# Drop rows with any N/A values in the respective columns and save to different files\n",
    "df_1yr = df.dropna(subset=[\"Price_Change_1Y\"])\n",
    "df_1yr.to_csv(\"../stocks_with_1yr_price_change2.csv\", index=False)\n",
    "\n",
    "df_5yr = df.dropna(subset=[\"Price_Change_5Y\"])\n",
    "df_5yr.to_csv(\"../stocks_with_5yr_price_change2.csv\", index=False)\n",
    "\n",
    "df_10yr = df.dropna(subset=[\"Price_Change_10Y\"])\n",
    "df_10yr.to_csv(\"../stocks_with_10yr_price_change2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix survivorship bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned file → data/stocks_cleaned_final.csv\n"
     ]
    }
   ],
   "source": [
    "# (macro columns kept, everything else NaN after delist) ----\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "DATA_DIR   = Path(\"data\")\n",
    "INPUT_CSV  = DATA_DIR / \"stocks_with_1yr_price_change2.csv\"\n",
    "OUTPUT_CSV = DATA_DIR / \"stocks_cleaned_final.csv\"\n",
    "END_DATE   = \"2024-10-15\"\n",
    "\n",
    "PRICE_COLS = [\"Open\", \"High\", \"Low\", \"Close\", \"Adjusted Close\"]\n",
    "MACRO_COLS = [\"CPI\", \"Fed_Funds_Rate\", \"GDP_Per_Capita\",\n",
    "              \"Inflation_Rate\", \"Real_GDP\", \"Treasury_Yield\",\n",
    "              \"Unemployment_Rate\"]                       # keep these\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def clean_delistings():\n",
    "    df = pd.read_csv(INPUT_CSV, parse_dates=[\"Date\"])\n",
    "    df.sort_values([\"Symbol\", \"Date\"], inplace=True)\n",
    "\n",
    "    calendar = pd.date_range(df[\"Date\"].min(), END_DATE, freq=\"B\")\n",
    "    frames = []\n",
    "\n",
    "    for sym, g in df.groupby(\"Symbol\"):\n",
    "        g = g.set_index(\"Date\").reindex(calendar)\n",
    "        g[\"Symbol\"] = sym\n",
    "\n",
    "        last_trade = g.dropna(subset=[\"Adjusted Close\"]).index.max()\n",
    "\n",
    "        # 1) Prices: flat‑line to END_DATE\n",
    "        g[PRICE_COLS] = g[PRICE_COLS].ffill()\n",
    "\n",
    "        # 2) Volume: zero past delist\n",
    "        g[\"Volume\"] = g[\"Volume\"].ffill()\n",
    "        g.loc[g.index > last_trade, \"Volume\"] = 0\n",
    "\n",
    "        # 3) Company‑specific fundamentals -> NaN past delist\n",
    "        company_cols = [c for c in g.columns\n",
    "                        if c not in PRICE_COLS + [\"Volume\", \"Symbol\", \"Date\"] + MACRO_COLS]\n",
    "        g.loc[g.index > last_trade, company_cols] = pd.NA\n",
    "\n",
    "        # (Macro columns left untouched — they're global)\n",
    "        frames.append(g.reset_index().rename(columns={\"index\": \"Date\"}))\n",
    "\n",
    "    cleaned = pd.concat(frames, ignore_index=True)\n",
    "    cleaned.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Saved cleaned file → {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_delistings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add future change columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file with future returns → data/stocks_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the cleaned data\n",
    "input_path = Path(\"data\") / \"stocks_cleaned_final.csv\"\n",
    "df = pd.read_csv(input_path, parse_dates=[\"Date\"])\n",
    "\n",
    "# Sort by symbol and date\n",
    "df = df.sort_values([\"Symbol\", \"Date\"])\n",
    "\n",
    "# Create columns for future price changes (1Y, 3Y, 5Y, 10Y)\n",
    "df[\"Future_Price_Change_1Y\"] = np.nan  # Initialize with NaN\n",
    "df[\"Future_Price_Change_3Y\"] = np.nan  # Initialize with NaN\n",
    "df[\"Future_Price_Change_5Y\"] = np.nan  # Initialize with NaN\n",
    "df[\"Future_Price_Change_10Y\"] = np.nan  # Initialize with NaN\n",
    "\n",
    "# Define trading days for different time periods\n",
    "DAYS_1Y = 252\n",
    "DAYS_3Y = 756    # 252 * 3\n",
    "DAYS_5Y = 1260   # 252 * 5\n",
    "DAYS_10Y = 2520  # 252 * 10\n",
    "\n",
    "# Process each stock separately\n",
    "for symbol, group in df.groupby(\"Symbol\"):\n",
    "    # Sort by date\n",
    "    group = group.sort_values(\"Date\")\n",
    "    \n",
    "    # Get the Adjusted Close values and indices\n",
    "    adj_close = group[\"Adjusted Close\"].values\n",
    "    group_indices = group.index.tolist()\n",
    "    \n",
    "    # Calculate 1-year future returns\n",
    "    for i in range(len(group) - DAYS_1Y):\n",
    "        current_price = adj_close[i]\n",
    "        future_price = adj_close[i + DAYS_1Y]\n",
    "        \n",
    "        if current_price > 0:  # Avoid division by zero\n",
    "            future_change = (future_price - current_price) / current_price\n",
    "            df.loc[group_indices[i], \"Future_Price_Change_1Y\"] = future_change\n",
    "    \n",
    "    # Calculate 3-year future returns\n",
    "    for i in range(len(group) - DAYS_3Y):\n",
    "        current_price = adj_close[i]\n",
    "        future_price = adj_close[i + DAYS_3Y]\n",
    "        \n",
    "        if current_price > 0:\n",
    "            future_change = (future_price - current_price) / current_price\n",
    "            df.loc[group_indices[i], \"Future_Price_Change_3Y\"] = future_change\n",
    "    \n",
    "    # Calculate 5-year future returns\n",
    "    for i in range(len(group) - DAYS_5Y):\n",
    "        current_price = adj_close[i]\n",
    "        future_price = adj_close[i + DAYS_5Y]\n",
    "        \n",
    "        if current_price > 0:\n",
    "            future_change = (future_price - current_price) / current_price\n",
    "            df.loc[group_indices[i], \"Future_Price_Change_5Y\"] = future_change\n",
    "    \n",
    "    # Calculate 10-year future returns\n",
    "    for i in range(len(group) - DAYS_10Y):\n",
    "        current_price = adj_close[i]\n",
    "        future_price = adj_close[i + DAYS_10Y]\n",
    "        \n",
    "        if current_price > 0:\n",
    "            future_change = (future_price - current_price) / current_price\n",
    "            df.loc[group_indices[i], \"Future_Price_Change_10Y\"] = future_change\n",
    "\n",
    "# Save the result\n",
    "output_path = Path(\"data\") / \"stocks_final.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved file with future returns → {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
