{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataAdjust.py\n",
    "3. Drop rows with any N/A values.\n",
    "4. Group the data by 'Symbol'.\n",
    "5. For each group, create a summary row containing:\n",
    "    - Symbol\n",
    "    - Start Date\n",
    "    - End Date\n",
    "    - Original Adjusted Close\n",
    "    - Final Adjusted Close\n",
    "    - Original Earnings\n",
    "    - Final Earnings\n",
    "    - Original P/E Ratio\n",
    "    - Final P/E Ratio\n",
    "6. Write the summary data to 'stocks_summary_one_row.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV\n",
    "df = pd.read_csv(\"stocks_calc_final.csv\")\n",
    "\n",
    "# Ensure Date is recognized as a datetime for proper sorting\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with any N/A values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Group by symbol\n",
    "grouped = df_clean.groupby(\"Symbol\", group_keys=True)\n",
    "\n",
    "summary_rows = []\n",
    "for symbol, group in grouped:\n",
    "    # Sort by Date so the first row is the earliest date, the last row is the latest date\n",
    "    group_sorted = group.sort_values(\"Date\")\n",
    "    first_row = group_sorted.iloc[0]\n",
    "    last_row = group_sorted.iloc[-1]\n",
    "    \n",
    "    # Create a single summary row for this symbol\n",
    "    summary_rows.append({\n",
    "        \"Symbol\": symbol,\n",
    "        \"Start Date\": first_row[\"Date\"].strftime(\"%Y-%m-%d\"),\n",
    "        \"End Date\": last_row[\"Date\"].strftime(\"%Y-%m-%d\"),\n",
    "        \"Original Adjusted Close\": first_row[\"Adjusted Close\"],\n",
    "        \"Final Adjusted Close\": last_row[\"Adjusted Close\"],\n",
    "        \"Original Earnings\": first_row[\"Earnings\"],\n",
    "        \"Final Earnings\": last_row[\"Earnings\"],\n",
    "        \"Original P/E Ratio\": first_row[\"P/E Ratio\"],\n",
    "        \"Final P/E Ratio\": last_row[\"P/E Ratio\"]\n",
    "    })\n",
    "\n",
    "# Create a new DataFrame and write to CSV\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(\"stocks_summary_one_row.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script processes stock data from a CSV file, calculates trailing twelve months (TTM) earnings per share (EPS) \n",
    "and price-to-earnings (P/E) ratios, and outputs the results to a new CSV file.\n",
    "Steps:\n",
    "1. Read stock data from 'stocks_calc_final.csv'.\n",
    "2. Convert the 'Date' column to datetime format and sort the data by 'Symbol' and 'Date'.\n",
    "3. Group the data by 'Symbol'.\n",
    "4. For each group, calculate the TTM EPS and P/E ratios:\n",
    "    - Initialize 'EPS (ttm)' and 'P/E (ttm)' columns with NaN values.\n",
    "    - For each row, if there are enough previous rows (189 days), calculate the TTM EPS as the sum of earnings \n",
    "      from the current row and the rows 63, 126, and 189 days prior.\n",
    "    - Calculate the TTM P/E ratio as the adjusted close price divided by the TTM EPS.\n",
    "5. Concatenate the processed groups and write the final DataFrame to 'stocks_calc_final_with_ttm.csv'.\n",
    "Output:\n",
    "- 'stocks_calc_final_with_ttm.csv': A CSV file containing the original data along with the calculated 'EPS (ttm)' \n",
    "  and 'P/E (ttm)' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"stocks_calc_final.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"Symbol\", \"Date\"])\n",
    "\n",
    "output_groups = []\n",
    "\n",
    "for symbol, group in df.groupby(\"Symbol\", group_keys=False):\n",
    "    # Sort by date, reset index so each row has a clean 0..N index\n",
    "    group = group.sort_values(\"Date\").reset_index(drop=True)\n",
    "    \n",
    "    # Initialize columns\n",
    "    group[\"EPS (ttm)\"] = np.nan\n",
    "    group[\"P/E (ttm)\"] = np.nan\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        if i >= 189:  # Enough rows\n",
    "            earnings_values = [\n",
    "                group.at[i, \"Earnings\"],\n",
    "                group.at[i-63, \"Earnings\"],\n",
    "                group.at[i-126, \"Earnings\"],\n",
    "                group.at[i-189, \"Earnings\"]\n",
    "            ]\n",
    "            if all(pd.notna(earnings_values)) and all(earnings_values):\n",
    "                eps_ttm = sum(earnings_values)\n",
    "                group.at[i, \"EPS (ttm)\"] = eps_ttm\n",
    "                if eps_ttm != 0:\n",
    "                    group.at[i, \"P/E (ttm)\"] = group.at[i, \"Adjusted Close\"] / eps_ttm\n",
    "    \n",
    "    output_groups.append(group)\n",
    "\n",
    "final_df = pd.concat(output_groups, ignore_index=True)\n",
    "final_df.to_csv(\"stocks_calc_final_with_ttm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(\"../stocks_calc_final_with_ttm.csv\")\n",
    "\n",
    "# Ensure Date is recognized as a datetime for proper sorting\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Sort by symbol and date\n",
    "df = df.sort_values([\"Symbol\", \"Date\"])\n",
    "\n",
    "# Calculate moving averages\n",
    "df[\"MA_50\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.rolling(window=50).mean())\n",
    "df[\"MA_200\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.rolling(window=200).mean())\n",
    "\n",
    "# Drop rows with any N/A values after moving averages calculation\n",
    "df = df.dropna()\n",
    "\n",
    "# Calculate price change over 1, 5, and 10 years\n",
    "df[\"Price_Change_1Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=252))\n",
    "df[\"Price_Change_5Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=1260))\n",
    "df[\"Price_Change_10Y\"] = df.groupby(\"Symbol\")[\"Adjusted Close\"].transform(lambda x: x.pct_change(periods=2520))\n",
    "\n",
    "df[\"MA_50/Adj_Close\"] = df[\"MA_50\"] / df[\"Adjusted Close\"]\n",
    "df[\"MA_200/Adj_Close\"] = df[\"MA_200\"] / df[\"Adjusted Close\"]\n",
    "\n",
    "# Drop rows with any N/A values in the respective columns and save to different files\n",
    "df_1yr = df.dropna(subset=[\"Price_Change_1Y\"])\n",
    "df_1yr.to_csv(\"../stocks_with_1yr_price_change.csv\", index=False)\n",
    "\n",
    "df_5yr = df.dropna(subset=[\"Price_Change_5Y\"])\n",
    "df_5yr.to_csv(\"../stocks_with_5yr_price_change.csv\", index=False)\n",
    "\n",
    "df_10yr = df.dropna(subset=[\"Price_Change_10Y\"])\n",
    "df_10yr.to_csv(\"../stocks_with_10yr_price_change.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
